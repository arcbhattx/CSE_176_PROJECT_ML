{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e6ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7376dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"MNISTmini.mat\")\n",
    "\n",
    "train_fea = data['train_fea1']\n",
    "train_gnd = data['train_gnd1']\n",
    "test_fea = data['test_fea1']\n",
    "test_gnd = data['test_gnd1']\n",
    "\n",
    "#print(np.shape(train_fea)) # (60000, 100)\n",
    "#print(np.shape(train_gnd)) # (60000, 1)\n",
    "#print(np.shape(test_fea)) # (10000, 100)\n",
    "#print(np.shape(test_gnd)) # (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33b10589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert labels as last column of feature matrix\n",
    "train_samples = np.column_stack((train_fea, train_gnd)) \n",
    "\n",
    "#print(train_samples)\n",
    "#print(train_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# sample (w/o replacement) 3000 samples from train_samples\n",
    "sub_samples = resample(train_samples, replace=False, n_samples=3000, random_state=20)\n",
    "\n",
    "# print(np.unique(sub_samples[:,-1])) # 10 total classes: 0-9, so to classify image as digit-0 -> class 1\n",
    "\n",
    "sub_train_fea = sub_samples[0:1000, :100]\n",
    "sub_train_gnd = sub_samples[0:1000, 100]\n",
    "\n",
    "sub_val_fea = sub_samples[1000:2000, :100]\n",
    "sub_val_gnd = sub_samples[1000:2000, 100]\n",
    "\n",
    "sub_test_fea = sub_samples[2000:3000, :100]\n",
    "sub_test_gnd = sub_samples[2000:3000, 100]\n",
    "\n",
    "# digit-5 samples:\n",
    "full_sample_digit_5 = sub_samples[2000:3000][sub_samples[2000:3000, -1] == 6] # digit-5 = class 6\n",
    "test_digit_5_fea = full_sample_digit_5[:50,:100]\n",
    "test_digit_5_gnd = full_sample_digit_5[:50, 100]\n",
    "\n",
    "#print(\"Full test sample matrix containing label for digit-5:\\n\", full_sample_digit_5)\n",
    "#print(\"Test sample features:\\n\", test_digit_5_fea) # 86/1000 total rows\n",
    "#print(\"Test sample labels:\\n\", test_digit_5_gnd) # 86/1000 rows are labeled as digit 5\n",
    "\n",
    "# digit-8 samples:\n",
    "full_sample_digit_8 = sub_samples[2000:3000][sub_samples[2000:3000, -1] == 9] # digit-8 = class 9\n",
    "test_digit_8_fea = full_sample_digit_8[:50, :100]\n",
    "test_digit_8_gnd = full_sample_digit_8[:50, 100]\n",
    "\n",
    "#print(\"Full sample matrix containing label for digit-8:\\n\", full_sample_digit_8)\n",
    "#print(\"Test sample features:\\n\", len(test_digit_8_fea)) # 115/1000 total rows \n",
    "#print(\"Test sample labels\\n\", len(test_digit_8_gnd)) # 115/1000 rows are labeled as digit 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "459fdc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Classifier:\n",
    "\n",
    "# Task: \n",
    "#   - Binary classification (digit-5 vs. digit-8)\n",
    "\n",
    "# Suggestions:\n",
    "#   - Use L2 regularization w/ hyperparameter determined via cross-validation\n",
    "#   - Use 'linlinear' training algorithm (solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16747d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split: 33/33/33:\n",
    "\n",
    "# Training set\n",
    "X_train = sub_train_fea\n",
    "y_train = sub_train_gnd\n",
    "\n",
    "# Validation set\n",
    "X_val = sub_val_fea\n",
    "y_val = sub_val_gnd\n",
    "\n",
    "# Test set (multi-class)\n",
    "X_test = sub_test_fea\n",
    "y_test = sub_test_gnd\n",
    "\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "\n",
    "# Test set (digit-5/class 6)\n",
    "X_test_digit_5 = test_digit_5_fea\n",
    "y_test_digit_5 = test_digit_5_gnd\n",
    "\n",
    "# Test set (digit-8/class 9)\n",
    "X_test_digit_8 = test_digit_8_fea\n",
    "y_test_digit_8 = test_digit_8_gnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4d726d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier  \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d5bb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 106 samples\n",
      "Class 2: 102 samples\n",
      "Class 3: 107 samples\n",
      "Class 4: 101 samples\n",
      "Class 5: 87 samples\n",
      "Class 6: 95 samples\n",
      "Class 7: 96 samples\n",
      "Class 8: 101 samples\n",
      "Class 9: 105 samples\n",
      "Class 10: 100 samples\n",
      "\n",
      "Class 1: 10.60%\n",
      "Class 2: 10.20%\n",
      "Class 3: 10.70%\n",
      "Class 4: 10.10%\n",
      "Class 5: 8.70%\n",
      "Class 6: 9.50%\n",
      "Class 7: 9.60%\n",
      "Class 8: 10.10%\n",
      "Class 9: 10.50%\n",
      "Class 10: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution to determine if classes are balanced/imbalanced\n",
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "for cls, count in zip(classes, counts):\n",
    "    print(f'Class {cls}: {count} samples')\n",
    "\n",
    "print()\n",
    "\n",
    "# Proportions for each class\n",
    "proportions = counts/len(y_train)\n",
    "for cls, prop in zip(classes, proportions):\n",
    "    print(f'Class {cls}: {prop*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6fb22397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (OvR) (1000 training samples): 0.457s\n",
      "Inference time (OvR) (100 total test samples): 0.00092s\n",
      "digit-5 (50 test samples): 0.860\n",
      "digit-8 (50 test samples): 0.660\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# One-vs-rest classifier with logistic regression as base estimator\n",
    "ovr_clf = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        # liblinear implements a trust region newton method\n",
    "        # n_jobs = 1 (1 core, no parallelism)\n",
    "        penalty='l2', solver='liblinear', max_iter=300, random_state=20, verbose=0\n",
    "    )\n",
    "    ).fit(X_train, y_train) # train classifier on multi-class training samples (1000 samples)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "print(f\"Training time (OvR) (1000 training samples): {train_time:.3f}s\")\n",
    "\n",
    "#ovr_clf.predict(X_test) # test on multi-class samples from test set\n",
    "#ovr_clf_score = ovr_clf.score(X_test, y_test)\n",
    "#print(ovr_clf_score)\n",
    "\n",
    "start = time.time()\n",
    "ovr_clf.predict(X_test_digit_5) # test classifier on digit-5 samples only from test set (50 samples)\n",
    "ovr_clf.predict(X_test_digit_8) # test classifier on digit-8 samples only from test set (50 samples)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "print(f'Inference time (OvR) (100 total test samples): {inference_time:.5f}s')\n",
    "\n",
    "ovr_clf_score_5 = ovr_clf.score(X_test_digit_5, y_test_digit_5)\n",
    "ovr_clf_score_8 = ovr_clf.score(X_test_digit_8, y_test_digit_8)\n",
    "\n",
    "# Score for digit-5, digit-8 classification over test set w/ one-vs-all classifier\n",
    "print(f\"digit-5 (50 test samples): {ovr_clf_score_5:.3f}\")\n",
    "print(f\"digit-8 (50 test samples): {ovr_clf_score_8:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3f6e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (OvO) (1000 training samples): 0.076s\n",
      "Inference time (OvO) (100 total test samples): 0.00629s\n",
      "digit-5 (50 test samples): 0.960\n",
      "digit-8 (50 test samples): 0.820\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# One-vs-one classifier with logistic regression as base estimator\n",
    "ovo_clf = OneVsOneClassifier(\n",
    "        LogisticRegression(\n",
    "            penalty='l2', solver='liblinear', max_iter=300, random_state=20, verbose=0\n",
    "        )\n",
    "    ).fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "print(f\"Training time (OvO) (1000 training samples): {train_time:.3f}s\")\n",
    "\n",
    "start = time.time()\n",
    "ovo_clf.predict(X_test_digit_5) # test classifier on digit-5 samples only from test set (50 samples)\n",
    "ovo_clf.predict(X_test_digit_8) # test classifier on digit-8 samples only from test set (50 samples)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "print(f'Inference time (OvO) (100 total test samples): {inference_time:.5f}s')\n",
    "\n",
    "ovo_clf_score_5 = ovo_clf.score(X_test_digit_5, y_test_digit_5)\n",
    "ovo_clf_score_8 = ovo_clf.score(X_test_digit_8, y_test_digit_8)\n",
    "\n",
    "# Score for digit-5, digit-8 classification w/ one-vs-one classifier\n",
    "print(f\"digit-5 (50 test samples): {ovo_clf_score_5:.3f}\")\n",
    "print(f\"digit-8 (50 test samples): {ovo_clf_score_8:.3f}\")\n",
    "\n",
    "#ovo_clf.predict(X_test) # test on multi-class samples\n",
    "#ovo_clf_score = ovo_clf.score(X_test, y_test)\n",
    "#print(ovo_clf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to explore: \n",
    "# (1) Why the classifier performs better on digit-5 compared to digit-8.\n",
    "# (2) Why the one-vs-one classifier performs slower during testing compared to one-vs-all? Probably due to the difference in the sample dimentions.\n",
    "# (3) Track the training and inference time for both types of classifiers.\n",
    "# (4) Use cross-validation to optimize the regularization hyperparameter.\n",
    "# (5) Plot validation vs training error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258497c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (OvR) (1000 training samples): 0.205s\n",
      "Inference time (OvR) (100 total test samples): 0.00495s\n",
      "digit-5 (50 test samples): 0.980\n",
      "digit-8 (50 test samples): 0.900\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start = time.time()\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "print(f\"Training time (OvR) (1000 training samples): {train_time:.3f}s\")\n",
    "\n",
    "#ovr_clf.predict(X_test) # test on multi-class samples from test set\n",
    "#ovr_clf_score = ovr_clf.score(X_test, y_test)\n",
    "#print(ovr_clf_score)\n",
    "\n",
    "start = time.time()\n",
    "model.predict(X_test_digit_5) # test classifier on digit-5 samples only from test set (50 samples)\n",
    "model.predict(X_test_digit_8) # test classifier on digit-8 samples only from test set (50 samples)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "print(f'Inference time (OvR) (100 total test samples): {inference_time:.5f}s')\n",
    "\n",
    "rfc_score_5 = model.score(X_test_digit_5, y_test_digit_5)\n",
    "rfc_score_8 = model.score(X_test_digit_8, y_test_digit_8)\n",
    "\n",
    "# Score for digit-5, digit-8 classification over test set w/ one-vs-all classifier\n",
    "print(f\"digit-5 (50 test samples): {rfc_score_5:.3f}\")\n",
    "print(f\"digit-8 (50 test samples): {rfc_score_8:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
