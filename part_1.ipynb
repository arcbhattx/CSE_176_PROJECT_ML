{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e6ab32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7376dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat(\"MNISTmini.mat\")\n",
    "\n",
    "train_fea = data['train_fea1']\n",
    "train_gnd = data['train_gnd1']\n",
    "test_fea = data['test_fea1']\n",
    "test_gnd = data['test_gnd1']\n",
    "\n",
    "#print(np.shape(train_fea)) # (60000, 100)\n",
    "#print(np.shape(train_gnd)) # (60000, 1)\n",
    "#print(np.shape(test_fea)) # (10000, 100)\n",
    "#print(np.shape(test_gnd)) # (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b10589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert labels as last column of feature matrix\n",
    "train_samples = np.column_stack((train_fea, train_gnd)) \n",
    "\n",
    "#print(train_samples)\n",
    "#print(train_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6ddcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# sample (w/o replacement) 3000 samples from train_samples\n",
    "sub_samples = resample(train_samples, replace=False, n_samples=3000, random_state=20)\n",
    "\n",
    "# print(np.unique(sub_samples[:,-1])) # 10 total classes: 0-9, so to classify image as digit-0 -> class 1\n",
    "\n",
    "sub_train_fea = sub_samples[0:1000, :100]\n",
    "sub_train_gnd = sub_samples[0:1000, -1]\n",
    "\n",
    "sub_val_fea = sub_samples[1000:2000, :100]\n",
    "sub_val_gnd = sub_samples[1000:2000, -1]\n",
    "\n",
    "sub_test_fea = sub_samples[2000:3000, :100]\n",
    "sub_test_gnd = sub_samples[2000:3000, -1]\n",
    "\n",
    "# digit-5 samples:\n",
    "full_sample_digit_5 = sub_samples[2000:3000][sub_samples[2000:3000, -1] == 6] # digit-5 = class 6\n",
    "test_digit_5_fea = full_sample_digit_5[:50,:100]\n",
    "test_digit_5_gnd = full_sample_digit_5[:50, -1]\n",
    "\n",
    "#print(\"Full test sample matrix containing label for digit-5:\\n\", full_sample_digit_5)\n",
    "#print(\"Test sample features:\\n\", test_digit_5_fea) # 86/1000 total rows\n",
    "#print(\"Test sample labels:\\n\", test_digit_5_gnd) # 86/1000 rows are labeled as digit 5\n",
    "\n",
    "# digit-8 samples:\n",
    "full_sample_digit_8 = sub_samples[2000:3000][sub_samples[2000:3000, -1] == 9] # digit-8 = class 9\n",
    "test_digit_8_fea = full_sample_digit_8[:50, :100]\n",
    "test_digit_8_gnd = full_sample_digit_8[:50, -1]\n",
    "\n",
    "#print(\"Full sample matrix containing label for digit-8:\\n\", full_sample_digit_8)\n",
    "#print(\"Test sample features:\\n\", len(test_digit_8_fea)) # 115/1000 total rows \n",
    "#print(\"Test sample labels\\n\", len(test_digit_8_gnd)) # 115/1000 rows are labeled as digit 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16747d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Validation/Test Split: 33/33/33 for multi-class classification:\n",
    "\n",
    "# Training set\n",
    "X_train = sub_train_fea\n",
    "y_train = sub_train_gnd\n",
    "\n",
    "# Validation set\n",
    "X_val = sub_val_fea\n",
    "y_val = sub_val_gnd\n",
    "\n",
    "# Test set\n",
    "X_test = sub_test_fea\n",
    "y_test = sub_test_gnd\n",
    "\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "\n",
    "# Binary classification (digit-5, digit-8)\n",
    "\n",
    "# Test set (digit-5/class 6)\n",
    "X_test_digit_5 = test_digit_5_fea\n",
    "y_test_digit_5 = test_digit_5_gnd\n",
    "\n",
    "# Test set (digit-8/class 9)\n",
    "X_test_digit_8 = test_digit_8_fea\n",
    "y_test_digit_8 = test_digit_8_gnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d5bb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "Digit-0: 106 samples\n",
      "Digit-1: 102 samples\n",
      "Digit-2: 107 samples\n",
      "Digit-3: 101 samples\n",
      "Digit-4: 87 samples\n",
      "Digit-5: 95 samples\n",
      "Digit-6: 96 samples\n",
      "Digit-7: 101 samples\n",
      "Digit-8: 105 samples\n",
      "Digit-9: 100 samples\n",
      "\n",
      "Class proportions:\n",
      "Digit-0: 10.60% of total samples.\n",
      "Digit-1: 10.20% of total samples.\n",
      "Digit-2: 10.70% of total samples.\n",
      "Digit-3: 10.10% of total samples.\n",
      "Digit-4: 8.70% of total samples.\n",
      "Digit-5: 9.50% of total samples.\n",
      "Digit-6: 9.60% of total samples.\n",
      "Digit-7: 10.10% of total samples.\n",
      "Digit-8: 10.50% of total samples.\n",
      "Digit-9: 10.00% of total samples.\n"
     ]
    }
   ],
   "source": [
    "classes, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "# Check class distribution to determine if classes are balanced/imbalanced\n",
    "print(\"Class distribution:\")\n",
    "for cls, count in zip(classes, counts):\n",
    "    print(f'Digit-{cls-1}: {count} samples')\n",
    "\n",
    "# Proportions for each class\n",
    "print(\"\\nClass proportions:\")\n",
    "proportions = counts/len(y_train)\n",
    "for cls, prop in zip(classes, proportions):\n",
    "    print(f'Digit-{cls-1}: {prop*100:.2f}% of total samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb22397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-rest classifier w/ LR (No cross-validation):\n",
      "Training time: 0.444s\n",
      "Inference time: 0.0007s\n",
      "Predicted class per test sample (digit-5): [ 2  6  6  6  6  6  6  6  6  6  6  6  6  2  6  6  6  6  4  6  6  6  6  6\n",
      "  6  6  6  3  6  5  6  6  6  6  6  6  6  6 10  6  6  6  6  6  6  6  2  6\n",
      "  6  6]\n",
      "Predicted class per test sample (digit-8): [3 9 9 4 9 8 9 3 8 4 9 3 9 9 9 9 9 9 7 9 8 9 9 9 9 9 8 9 9 7 9 4 7 8 9 8 9\n",
      " 9 9 2 9 9 9 9 9 8 9 9 9 9]\n",
      "Model prediction accuracy (digit-5): 0.860\n",
      "Model prediction accuracy (digit-8): 0.660 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier  \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# One-vs-rest classifier with logistic regression as base estimator\n",
    "ovr_clf = OneVsRestClassifier(\n",
    "    LogisticRegression(\n",
    "        # liblinear implements a trust region newton method\n",
    "        # n_jobs = 1 (1 core, no parallelism)\n",
    "        penalty='l2', solver='liblinear', max_iter=1000, random_state=20, verbose=0, n_jobs=1\n",
    "    )\n",
    "    ).fit(X_train, y_train) # train classifier on multi-class training samples (1000 samples)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_5 = ovr_clf.predict(X_test_digit_5)\n",
    "y_pred_8 = ovr_clf.predict(X_test_digit_8)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "acc_5 = accuracy_score(y_true=y_test_digit_5, y_pred=y_pred_5)\n",
    "acc_8 = accuracy_score(y_true=y_test_digit_8, y_pred=y_pred_8)\n",
    "\n",
    "# Score for digit-5, digit-8 classification w/ one-vs-rest classifier\n",
    "print(\"One-vs-rest classifier w/ LR (No cross-validation):\")\n",
    "print(f\"Training time: {train_time:.3f}s\")\n",
    "print(f\"Inference time: {inference_time:.4f}s\")\n",
    "print(f\"Predicted class per test sample (digit-5): {y_pred_5}\")\n",
    "print(f\"Predicted class per test sample (digit-8): {y_pred_8}\")\n",
    "print(f\"Model prediction accuracy (digit-5): {acc_5:.3f}\")\n",
    "print(f\"Model prediction accuracy (digit-8): {acc_8:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3f6e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-one classifier w/ LR (No cross-validation):\n",
      "Training time: 0.060s\n",
      "Inference time: 0.0061s\n",
      "Predicted class per test sample (digit-5 = class 6): [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "Predicted class per test sample (digit-8 = class 9): [3 9 9 4 9 8 9 3 9 9 9 9 9 9 9 9 9 9 8 9 9 9 9 9 9 9 9 9 9 9 9 4 7 9 9 4 9\n",
      " 9 9 2 9 9 9 9 9 9 9 9 9 9]\n",
      "Model prediction accuracy (digit-5): 0.960\n",
      "Model prediction accuracy (digit-8): 0.820 \n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# One-vs-one classifier with logistic regression as base estimator\n",
    "ovo_clf = OneVsOneClassifier(\n",
    "        LogisticRegression(\n",
    "            penalty='l2', solver='liblinear', max_iter=1000, random_state=20, verbose=0, n_jobs=1\n",
    "        )\n",
    "    ).fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_5 = ovo_clf.predict(X_test_digit_5) # test classifier on digit-5 samples only from test set (50 samples)\n",
    "y_pred_8 = ovo_clf.predict(X_test_digit_8) # test classifier on digit-8 samples only from test set (50 samples)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "acc_5 = accuracy_score(y_true=y_test_digit_5, y_pred=y_pred_5)\n",
    "acc_8 = accuracy_score(y_true=y_test_digit_8, y_pred=y_pred_8)\n",
    "\n",
    "# Score for digit-5, digit-8 classification w/ one-vs-one classifier\n",
    "print(\"One-vs-one classifier w/ LR (No cross-validation):\")\n",
    "print(f\"Training time: {train_time:.3f}s\")\n",
    "print(f\"Inference time: {inference_time:.4f}s\")\n",
    "print(f\"Predicted class per test sample (digit-5 = class 6): {y_pred_5}\")\n",
    "print(f\"Predicted class per test sample (digit-8 = class 9): {y_pred_8}\")\n",
    "print(f\"Model prediction accuracy (digit-5): {acc_5:.3f}\")\n",
    "print(f\"Model prediction accuracy (digit-8): {acc_8:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188b1e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-rest w/ LR w/ cross-validation:\n",
      "Training time: 20.240s\n",
      "Inference time: 0.0007s\n",
      "Predicted class per test sample (digit-5 = class 6): [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "Predicted class per test sample (digit-8 = class 9): [3 9 9 9 9 1 9 3 4 9 9 1 9 9 9 9 9 9 7 9 9 9 9 9 9 9 7 9 9 7 9 4 7 9 9 4 9\n",
      " 9 9 2 9 9 9 9 9 5 9 9 9 9]\n",
      "Model prediction accuracy (digit-5): 0.960\n",
      "Model prediction accuracy (digit-8): 0.740 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# One-vs-rest logistic regression w/ cross-validation\n",
    "start = time.time()\n",
    "clf = OneVsRestClassifier(\n",
    "    LogisticRegressionCV(Cs=10, cv=5, penalty='l2', solver='liblinear', max_iter=1000, random_state=20, n_jobs=1)\n",
    ").fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_5 = clf.predict(X_test_digit_5)\n",
    "y_pred_8 = clf.predict(X_test_digit_8)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "acc_5 = accuracy_score(y_true=y_test_digit_5, y_pred=y_pred_5)\n",
    "acc_8 = accuracy_score(y_true=y_test_digit_8, y_pred=y_pred_8)\n",
    "\n",
    "print(\"One-vs-rest w/ LR w/ cross-validation:\")\n",
    "print(f\"Training time: {train_time:.3f}s\")\n",
    "print(f\"Inference time: {inference_time:.4f}s\")\n",
    "print(f\"Predicted class per test sample (digit-5 = class 6): {y_pred_5}\")\n",
    "print(f\"Predicted class per test sample (digit-8 = class 9): {y_pred_8}\")\n",
    "print(f\"Model prediction accuracy (digit-5): {acc_5:.3f}\")\n",
    "print(f\"Model prediction accuracy (digit-8): {acc_8:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85eda184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-one w/ LR (w/ cross-validation):\n",
      "Training time: 1.911s\n",
      "Inference time: 0.0063s\n",
      "Predicted class per test sample (digit-5 = class 6): [6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 4 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "Predicted class per test sample (digit-8 = class 9): [3 9 9 9 9 8 9 3 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 4 7 9 9 4 9\n",
      " 9 9 2 9 9 9 9 9 9 9 9 9 9]\n",
      "Model prediction accuracy (digit-5): 0.960\n",
      "Model prediction accuracy (digit-8): 0.860 \n"
     ]
    }
   ],
   "source": [
    "# One-vs-one logistic regression w/ cross-validation\n",
    "start = time.time()\n",
    "clf = OneVsOneClassifier(\n",
    "    LogisticRegressionCV(Cs=10, cv=5, penalty='l2', solver='liblinear', max_iter=1000, random_state=20, n_jobs=1)\n",
    ").fit(X_train, y_train)\n",
    "stop = time.time()\n",
    "\n",
    "train_time = stop - start\n",
    "\n",
    "start = time.time()\n",
    "y_pred_5 = clf.predict(X_test_digit_5)\n",
    "y_pred_8 = clf.predict(X_test_digit_8)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "acc_5 = accuracy_score(y_true=y_test_digit_5, y_pred=y_pred_5)\n",
    "acc_8 = accuracy_score(y_true=y_test_digit_8, y_pred=y_pred_8)\n",
    "\n",
    "print(\"One-vs-one w/ LR (w/ cross-validation):\")\n",
    "print(f\"Training time: {train_time:.3f}s\")\n",
    "print(f\"Inference time: {inference_time:.4f}s\")\n",
    "print(f\"Predicted class per test sample (digit-5 = class 6): {y_pred_5}\")\n",
    "print(f\"Predicted class per test sample (digit-8 = class 9): {y_pred_8}\")\n",
    "print(f\"Model prediction accuracy (digit-5): {acc_5:.3f}\")\n",
    "print(f\"Model prediction accuracy (digit-8): {acc_8:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258497c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier (w/ cross-validation to determine # of trees)\n",
      "Training time: 48.477s\n",
      "Best score: 0.879\n",
      "Best parameters: {'n_estimators': np.int64(374)}\n",
      "Inference time: 0.0175s\n",
      "Model prediction accuracy (digit-5): 0.960\n",
      "Model prediction accuracy (digit-8): 0.840 \n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "np.random.seed(20)\n",
    "param_dist = {\n",
    "    'n_estimators': np.random.randint(100, 1001, 100)\n",
    "}\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=20, n_jobs=1)\n",
    "\n",
    "# n_jobs=-1: use all available cores for parallel training\n",
    "start = time.time()\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_clf, param_distributions=param_dist, cv=5, scoring='accuracy', random_state=20\n",
    ").fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "train_time = end - start\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "start = time.time()\n",
    "rf_acc_5 = best_model.score(X_test_digit_5, y_test_digit_5)\n",
    "rf_acc_8 = best_model.score(X_test_digit_8, y_test_digit_8)\n",
    "end = time.time()\n",
    "\n",
    "inference_time = end - start\n",
    "\n",
    "# Score for digit-5, digit-8 classification over test set random forest classifier\n",
    "print(\"Random Forest Classifier (w/ cross-validation to determine # of trees)\")\n",
    "print(f\"Training time: {train_time:.3f}s\")\n",
    "print(f\"Best score: {random_search.best_score_:.3f}\")\n",
    "print(f\"Best parameters: {random_search.best_params_}\")\n",
    "print(f\"Inference time: {inference_time:.4f}s\")\n",
    "#print(f\"Predicted class per test sample (digit-5 = class 6): {rf_y_pred_5}\")\n",
    "#print(f\"Predicted class per test sample (digit-8 = class 9): {rf_y_pred_8}\")\n",
    "print(f\"Model prediction accuracy (digit-5): {rf_acc_5:.3f}\")\n",
    "print(f\"Model prediction accuracy (digit-8): {rf_acc_8:.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e0ae815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore parallelized training/testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
