{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d1db4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Colab Setup\n",
    "\n",
    "# %%\n",
    "# Colab environment setup\n",
    "!git clone https://github.com/neurodata/SPORF.git\n",
    "%cd /content/SPORF/Python\n",
    "!apt-get update\n",
    "!apt-get install -y build-essential cmake python3-dev libomp-dev libeigen3-dev  # Ubuntu/Debian\n",
    "!python setup.py clean --all\n",
    "!pip install -e .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e9fe8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Imports\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from rerf.RerF import fastPredict, fastPredictPost, fastRerF\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1c335",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Part 1: Data Cleaning\n",
    "\n",
    "# %%\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"./datasets/social_media_vs_productivity.csv\")\n",
    "\n",
    "# %%\n",
    "# Check columns\n",
    "df.columns\n",
    "\n",
    "# %%\n",
    "# Preview first rows\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "# Dataset info\n",
    "df.info()\n",
    "\n",
    "# %%\n",
    "# Unique values for object and boolean datatypes\n",
    "# To be turned into numeric values for modeling\n",
    "df_columns = df.columns\n",
    "\n",
    "for column in df_columns:\n",
    "    if df[column].dtype == \"object\" or df[column].dtype == \"bool\":\n",
    "        print(df[column].unique())\n",
    "\n",
    "# %%\n",
    "# Convert all unique values to numbers through mapping\n",
    "for column in df_columns:\n",
    "    if df[column].dtype == \"object\" or df[column].dtype == \"bool\":\n",
    "        unique_values = df[column].unique()\n",
    "        mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "        df[column] = df[column].map(mapping)\n",
    "\n",
    "# %%\n",
    "# Preview after mapping\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "# Replace NaN values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# %%\n",
    "# Preview after filling NaNs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ee88c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"/content/social_media_vs_productivity_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629bd5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Part 2: Regression Using SPORF\n",
    "\n",
    "# %%\n",
    "# Load cleaned dataset\n",
    "df = pd.read_csv('/content/social_media_vs_productivity_cleaned.csv')\n",
    "\n",
    "# %%\n",
    "# features that don't have anything to do with productivity, as well as the output.\n",
    "input_invalid_columns = ['social_platform_preference', 'perceived_productivity_score', 'actual_productivity_score', 'Unnamed: 0']\n",
    "\n",
    "# %%\n",
    "features = df.drop(columns=input_invalid_columns)\n",
    "features.head()\n",
    "\n",
    "# %%\n",
    "# Output column\n",
    "output = df['actual_productivity_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da82e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Convert to numpy arrays\n",
    "input_features = features.to_numpy()\n",
    "outputs = output.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308b843",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Split dataset: train/test and train/validation\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    input_features, outputs, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2c5a0c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Check shapes\n",
    "print(f\"X_train shape {X_train.shape}\")\n",
    "print(f\"X_test shape {X_test.shape}\")\n",
    "print(f\"y_train shape {y_train.shape}\")\n",
    "print(f\"y_test shape {y_test.shape}\")\n",
    "print(\"Validation:\")\n",
    "print(f\"X_val shape {X_val.shape}\")\n",
    "print(f\"y_val shape {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c96d9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "# Train Randomer Forest\n",
    "forest = fastRerF(\n",
    "    X=X_train,\n",
    "    Y=y_train,\n",
    "    forestType=\"rfBase\",  # regression forest\n",
    "    trees=500,\n",
    "    maxDepth=20,\n",
    "    minParent=5,\n",
    "    numCores=cpu_count()\n",
    ")\n",
    "\n",
    "forest.printParameters()\n",
    "\n",
    "# %%\n",
    "# Predictions\n",
    "train_pred = fastPredict(X_train, forest)\n",
    "test_pred = fastPredict(X_test, forest)\n",
    "\n",
    "# Compute errors\n",
    "train_rmse = mean_squared_error(y_train, train_pred)\n",
    "test_rmse = mean_squared_error(y_test, test_pred)\n",
    "train_mae = mean_absolute_error(y_train, train_pred)\n",
    "test_mae = mean_absolute_error(y_test, test_pred)\n",
    "\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Test RMSE:\", test_rmse)\n",
    "print(\"Train MAE:\", train_mae)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "\n",
    "# %%\n",
    "# Basic stats of output\n",
    "print(\"Min:\", outputs.min())\n",
    "print(\"Max:\", outputs.max())\n",
    "print(\"Range:\", outputs.max() - outputs.min())\n",
    "print(\"Mean:\", outputs.mean())\n",
    "print(\"Std:\", outputs.std())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
